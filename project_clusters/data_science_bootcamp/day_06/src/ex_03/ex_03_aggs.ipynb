{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise *03*: Aggregations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a connection to the database using the library *sqlite3*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "from sqlite3 import Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_path: str = \"../../data/checking_logs.sqlite\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn: Connection = sqlite3.connect(db_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the schema of the table *test*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from pandas import DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query: str = \"PRAGMA table_info(test);\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema: DataFrame = pd.io.sql.read_sql(\n",
    "    sql_query,\n",
    "    conn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get only the first *10* rows of the table *test* to check what the table looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query: str = \"\"\"\n",
    "                 SELECT\n",
    "                     *\n",
    "                 FROM\n",
    "                     test\n",
    "                 LIMIT\n",
    "                     10;\n",
    "                 \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows: DataFrame = pd.io.sql.read_sql(\n",
    "    sql_query,\n",
    "    conn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find among all the users the minimum value of the delta between the first commit of the user and the deadline of the corresponding lab using only one query:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Do this by joining the table with the table *deadlines*:\n",
    "* The difference should be displayed in hours:\n",
    "* Do not take the lab *’project1’* into account, it has longer deadlines and will be an outlier:\n",
    "* The value should be stored in the dataframe `df_min` with the corresponding *uid*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query: str = \"\"\"\n",
    "                 SELECT\n",
    "                     test.uid AS uid,\n",
    "                     MIN((unixepoch(test.first_commit_ts) - deadlines.deadlines) / 3600) AS min_delt\n",
    "                 FROM\n",
    "                     test\n",
    "                 INNER JOIN\n",
    "                     deadlines ON test.labname = deadlines.labs\n",
    "                 WHERE\n",
    "                     test.labname != 'project1';\n",
    "                 \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_min: DataFrame = pd.io.sql.read_sql(\n",
    "    sql_query,\n",
    "    conn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do the same thing, but for the maximum, using only one query, the dataframe name is `df_max`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query: str = \"\"\"\n",
    "                 SELECT\n",
    "                     test.uid AS uid,\n",
    "                     MAX((unixepoch(test.first_commit_ts) - deadlines.deadlines) / 3600) AS max_delt\n",
    "                 FROM\n",
    "                     test\n",
    "                 INNER JOIN\n",
    "                     deadlines ON test.labname = deadlines.labs\n",
    "                 WHERE\n",
    "                     test.labname != 'project1';\n",
    "                 \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_max: DataFrame = pd.io.sql.read_sql(\n",
    "    sql_query,\n",
    "    conn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do the same thing but for the average, using only one query, this time your dataframe should not include the *uid* column, and the dataframe name is `df_avg`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query: str = \"\"\"\n",
    "                 SELECT\n",
    "                     AVG((unixepoch(test.first_commit_ts) - deadlines.deadlines) / 3600) AS avg_delt\n",
    "                 FROM\n",
    "                     test\n",
    "                 INNER JOIN\n",
    "                     deadlines ON test.labname = deadlines.labs\n",
    "                 WHERE\n",
    "                     test.labname != 'project1';\n",
    "                 \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avg: DataFrame = pd.io.sql.read_sql(\n",
    "    sql_query,\n",
    "    conn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We want to test the hypothesis that the users who visited the *newsfeed* just a few times have the lower delta between the first commit and the deadline. To do this, you need to calculate the correlation coefficient between the number of pageviews and the difference:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Using only one query, create a table with the columns: *uid*, *avg_diff*, *pageviews*:\n",
    "* *uid* is the uids that exist in the test:\n",
    "* *avg_diff* is the average delta between the first commit and the lab deadline per user:\n",
    "* *pageviews* is the number of *Newsfeed* visits per user:\n",
    "* Do not take the lab *’project1’* into account:\n",
    "* Store it to the dataframe `views_diff`:\n",
    "* Use the *Pandas* method `corr()` to calculate the correlation coefficient between the number of *pageviews* and the *difference*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query: str = \"\"\"\n",
    "                 SELECT\n",
    "                     test.uid AS uid,\n",
    "                     AVG((unixepoch(test.first_commit_ts) - deadlines.deadlines) / 3600) AS avg_diff,\n",
    "                     COUNT(pageviews.datetime) AS pageviews\n",
    "                 FROM\n",
    "                     test\n",
    "                 INNER JOIN\n",
    "                     deadlines ON test.labname = deadlines.labs\n",
    "                 LEFT OUTER JOIN\n",
    "                     pageviews ON test.uid = pageviews.uid\n",
    "                 WHERE\n",
    "                     test.labname != 'project1'\n",
    "                 GROUP BY\n",
    "                     test.uid;\n",
    "                 \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "views_diff: DataFrame = pd.io.sql.read_sql(\n",
    "    sql_query,\n",
    "    conn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.1858"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(round(\n",
    "    views_diff[\"pageviews\"].corr(views_diff[\"avg_diff\"]),\n",
    "    4\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# views_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Close the connection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
